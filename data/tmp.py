from tree_sitter import Language, Parser
from query_pattern import JAVA_QUERY
from treelib import Tree
from ast_node import ASTNode
import tree_sitter
import uuid
import os


def generate_ast_key(file_name: str, func_name: str, parsed_node: tree_sitter.Node) -> str:
    """ Generate unique key value for each ASTNode

    attributes:
        file_name -- name of the file including current node\\
        parsed_node -- instance of tree_sitter Node is parsed now
    
    returns:
        key_value -- unique key string for parsed_node
    """
    # construct unique string for each tree_sitter Node
    key_str = file_name + '-' + func_name + '-' + parsed_node.type + '-' + str(parsed_node.start_byte) + '-' + str(parsed_node.end_byte)
    key_value = uuid.uuid3(uuid.NAMESPACE_DNS, key_str)
    key_value = str(key_value).replace('-', '')

    return key_value

class Queue():
    """Construct the queue structure using list
    """
    def __init__(self) -> None:
        self.__list = list()
    
    def is_empty(self):
        return self.__list == []
    
    def push(self, data):
        self.__list.append(data)
    
    def pop(self):
        if self.is_empty():
            return False
        
        return self.__list.pop(0)


def build_func_sast(file_name: str, func_name: str, func_tree : tree_sitter.Node, src_code : bytes, exclude_type: list) -> Tree:
    """Build simplified AST (sast) with function as the basic unit

    attributes:
        file_name -- name of the file including current function\\
        func_tree -- function ast generated by tree-sitter\\
        src_code -- serial source code for token querying\\
        exclude_type -- identifier types ignored
    
    returns:
        s_ast -- simplified ast organized by ASTNode
    """
    s_ast = Tree()
    
    # create root node for this function
    root_node = func_tree
    root_key = generate_ast_key(file_name, func_name, root_node)
    has_child = len(root_node.children)
    if not has_child:
        root_token = src_code[root_node.start_byte:root_node.end_byte]
    else:
        root_token = ''
    root_ast = ASTNode(root_key, root_node.type, root_token, root_node.start_byte, root_node.end_byte)
    s_ast.create_node(tag=root_node.type, identifier=root_key, data=root_ast)

    query = JAVA_QUERY()
    ret_node = query.method_ret_query().captures(root_node)[0][0]
    
    # create ret node for each ast
    ret_key = generate_ast_key(file_name, func_name, ret_node)
    ret_token = src_code[ret_node.start_byte:ret_node.end_byte].decode('utf8')
    ret_astnode = ASTNode(ret_key, 'ret_type', ret_token, ret_node.start_byte, ret_node.end_byte)

    queue = Queue()
    queue.push(root_node)
    while not queue.is_empty():
        current_node = queue.pop()

        for child in current_node.children:
            child_type = str(child.type)
            if child_type in exclude_type:
                continue
            child_key = generate_ast_key(file_name, func_name, child)
            child_token = ''
            has_child = len(child.children) > 0
            if not has_child:
                child_token = src_code[child.start_byte:child.end_byte].decode('utf8')
            parent_identifier = generate_ast_key(file_name, func_name, current_node)
            s_ast.create_node(tag=child_type, identifier=child_key, parent=parent_identifier, data=ASTNode(child_key, child_type, child_token, child.start_byte, child.end_byte))

            queue.push(child)
    if s_ast.get_node(ret_key) == None:
        exit(-1)
    
    # remove return parameter node, and place it as return node.
    s_ast.remove_node(ret_key)
    s_ast.create_node(tag=ret_node.type, identifier=ret_key, parent=root_key, data=ret_astnode)

    return s_ast


def java_parser(file_path: str) -> list:
    """ Parse Java source code file & extract function unit

    attributes:
        file_path -- the path of Java source file.
    
    returns:
        func_list -- list including all function in current file.
    """
    func_list = []
    parser = Parser()
    parser.set_language(Language('/home/zixian/PycharmProjects/semantic_graph_code_code_clone/data/my-languages.so', 'java'))
    with open(file_path, 'rb') as f:
        serial_code = f.read()
        code_ast = parser.parse(serial_code)
    
    root_node = code_ast.root_node

    # print(root_node.sexp())

    # obtain file name
    file_name = "11.java"

    query = JAVA_QUERY()
    # query import headers (e.g., import java.util.Scanner)
    # import_header = query.import_header_query().captures(root_node)
    # import_header = [serial_code[x[0].start_byte:x[0].end_byte-1].decode('utf8') for x in import_header]

    # # query field parameters (e.g., class variables)
    # field_params = query.class_filed_query().captures(root_node)
    # field_params = [serial_code[x[0].start_byte:x[0].end_byte].decode('utf8') for x in field_params]

    # query methods
    _methods = query.class_method_query().captures(root_node)

    exclude_type = [",","{",";","}",")","(",'"',"'","`",""," ","[]","[","]",":",".","''","'.'","b", "\\", "'['", "']","''", "comment", "@", "?"]

    for _method in _methods:
        _m_name_tmp = query.method_declaration_query().captures(_method[0])
        _m_name = serial_code[_m_name_tmp[0][0].start_byte:_m_name_tmp[0][0].end_byte].decode('utf8')
        # _m_param_tmp = query.method_parameters_query().captures(_method[0])
        # _m_param_type, _m_param_name = align_query_result(_m_param_tmp, 'type', 'name')
        # _m_param_type = [serial_code[x.start_byte:x.end_byte].decode('utf8') for x in _m_param_type]
        # _m_param_name = [serial_code[x.start_byte:x.end_byte].decode('utf8') for x in _m_param_name]
        sast = build_func_sast(file_name, _m_name, _method[0], serial_code, exclude_type)

        # cur_func = FunUnit(sast, file_name, _m_name, _m_param_type, _m_param_name, import_header, field_params)
        # func_list.append(cur_func)
    
    return func_list


if __name__ == '__main__':
    java_parser('/home/zixian/PycharmProjects/semantic_graph_code_code_clone/benchmark/dataset/BCB_tailor/bigclonebench/21386162.java')